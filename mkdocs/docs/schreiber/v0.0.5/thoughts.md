# Thoughts on R2 and Cloesce Services

Up until now, the only focus for Cloesce has been D1 and Workers. We've created Models, which are abstractions over D1 and Workers (a model represents a table, it's method endpoints).

In v0.0.5, we will introduce Services and Cloudflare R2, both of which are not necessarily tied to a model.

## Services

Workers endpoints do not always need to exist on a model. For instance, if my application exposed only basic REST endpoints, I shouldn't have to create a SQL table and run migrations just to get the program running. We will introduce Services, a group of methods under a namespace, optionally capturing a closure of injected instances.

It will be important that a Cloesce project can run _without_ having a database defined.

For example:

```ts
@Service
export class FooService {
    @POST
    async foo(...) {} // instantiated method

    @GET
    static bar(...) {} // static method

    foo() {} // doesn't have to be exposed as a Worker endpoint
}
```

Exposed static methods will be supported, but maybe we should have a warning along the lines of "why are you doing this", since there isn't really a good reason.

Attributes on a FooService _must_ be dependency injected, and we will assume that is the case by default.

```ts
@Service
export class FooService {
    env: Env;

    async foo(...) {
        this.env.db ...
        this.bar ...
    }

    static bar(...) {
        // static, can't use env or bar
    }
}
```

Services will all be apart of the default dependency injection container, allowing them to be injected in both Service and Model methods.

```ts
@Service
export class FooService {
    env: Env;
    bar: BarService;

    // or equivalently
    func(@Inject bar: BarService) {
        ...
    }
}
```

We will have to detect cyclical service dependencies much like we do with Models, raising an error. We could allow cyclical dependencies through lazy instantiation, but that can be saved for a later time.

### Client Side

All attributes of a Service are injected; all methods will be static on the client class:

```ts
@Service
export class FooService {
  env: Env;
  bar: BarService;

  @POST
  foo() {}
}

// => client code
export class FooService {
  static async foo(): Promise<HttpResult<void>> {...}
}
```

### Cloesce Router Interface with Services

We've defined services in such a way that it aligns closely with how Models are routed.

A new important step will be initializing and injecting all services, meaning we construct every object in topological order and insert it into the DI container.

We will also want to rename the `Model Middleware` to `Namespace Middleware` (or some better name), as it should apply to both Models and Services.

Lastly, Model Hydration will have to be more generic, hydrating a Model or just getting the injected Service.

![Cloesce Router Interface](../../assets//Cloesce%20Router%20with%20Services.png)

## Blobs and R2

R2 is Cloudflares object storage platform. Objects are stored under a namespace called a bucket, with each value having it's own unique key. Keys are decided by the developer, and are not generated by R2.

Files, images, and other kinds of data are classified as blobs (binary large objects). Cloesce operates using Workers, and an important limitation of Workers is that the maximum amount of memory of any instance is 128MB. This means large objects cannot be be fully buffered in memory for a worker, and must be streamed to some destination using the Worker as a pipe.

Since R2 is S3 compatible, an alternative is supprted via signed uploads and signed downloads. Essentially, a Worker can query the Cloudflare API to ask "give me cryptographic permission to do this file upload/download", and a link will be returned like:

```text
https://bucket.r2.cloudflarestorage.com/uploads/123.png?X-Amz-Expires=600&X-Amz-Signature=abc123...",
```

The client is then responsible for uploading their file to the link. A typical pattern servers follow is having some upload endpoint `foo/upload`, and then having some complete endpoint `foo/upload/complete`, where they can tell the server "I've successfully done an upload". Note that an upload could fail, in which an orphaned R2 blob would exist, forcing some periodic orphan killer to exist.

For the scope of Cloesce, orchestrating the signed upload process to R2 seems out of scope (at least for now). However, there is no reason for us to prohibit uploading and downloading blobs.

### Blob, Stream, Media Type

We will need to introduce a CIDL Type `Blob`, which indicates to our compiler that this value must be both uploaded (from the client) and received (from the worker) differently than others. `Blob` will be a valid SQL column type.

Currently, incoming data is assumed to be `application/json`, and outgoing data is always `application/json`. JSON is meant for structured data, under a strict text format. File uploads are typically done as `application/octet-stream`, and a combination of the two is done as `multipart/form-data`

#### Only Blob

Let's imagine a method takes a Blob as an argument (assume this is a Cloesce type as well as a TS type):

```ts
@POST
fooBlob(blob: Blob) {}
```

This is simple enough, our client needs to send an octet stream:

```ts
// Client
const blob = new Blob([someUint8Array], { type: "application/octet-stream" });

await fetch("/api/upload", {
  method: "POST",
  headers: {
    "Content-Type": "application/octet-stream",
  },
  body: blob,
});
```

Our worker will have to know _not_ to load the buffer in memory, but to leave it as is. Instead of accepting a blob, we should accept a `ReadableStream<Uint8Array>`, which we can just alias as `Stream`

```ts
@POST
async fooBlob(stream: Stream) {
  ...
}
```

It's reasonable to not want a `Stream` and just want the body to be serialized as a Blob, which the previous method definition would do.

In the reverse case, where a Worker sends to a client, the same logic will have to take place, but based off the return type of a method:

```ts
@Service
class BlobService {
  @GET
  async getBlob(): Blob

  @GET
  async getStream(): Stream
}
```

#### Blob alongside JSON

It's reasonable to have methods that have both Blobs and JSON, ex:

```ts
@POST
fooBlob(blob: Blob, obj: SomeObj, color: string) {}
```

However, this comes with a caveat. We _cannot_ use a Stream here, because there are other parameters in the mix. `FormData` is the only type that supports both blobs and JSON data. This means that we are forced to load the entire buffer in memory, potentially hitting the memory limit. A sufficient warning should be displayed in this case.

```ts
// Client
const blob = new Blob(["hello world"], { type: "text/plain" });
const form = new FormData();
form.append("blob", blob, "hello.txt");
form.append("json", JSON.stringify({
    obj: {...}
    color: "..."
}))

const response = await fetch("https://example.com/upload", {
  method: "POST",
  body: form,
});
```

```ts
// Backend
const data request.formData();
const blob = form.get("blob");
const json = JSON.parse(form.get("json"));
fooBlob(blob, json.obj, json.color);
```

#### Uploading Multiple Blobs & Composition

Given a scenario:

```ts
class Parent {
  blobs: Blob[];
  children: Child[];
}

class Child {
  blobs: Blob[];
  favoriteBlob: Blob;
}
```

How do we serialize the objects into FormData and deserialize appropriately? We can map each blob to an index in a flattened blob array:

```ts
function extractBlobs(value, blobs) {
  if (value instanceof Blob) {
    return { __blobIndex: blobs.push(value) - 1 };
  }

  if (Array.isArray(value)) {
    return value.map((v) => extractBlobs(v, blobs));
  }

  if (value && typeof value === "object") {
    return Object.fromEntries(
      Object.entries(value).map(([k, v]) => [k, extractBlobs(v, blobs)])
    );
  }

  return value;
}

function toJson(obj) {
  const blobs = [];
  const replaced = extractBlobs(obj, blobs);
  return { json: JSON.stringify(replaced), blobs };
}

const { json, blobs } = toJson(parent);
// => now blobs contains [...parent.blobs, ...parent.flatMap(p => p.children.map(c => [c.favoriteBlob, ...c.blobs]))]
//
// and each blob has been replaced with an index ie Child { favoriteBlob: K, blobs: [K + 1, K + 2, K + 3, ...]}
```

When serializing, we should do so with respect to a blob array.

```ts
function parseWithBlobs(json, blobs) {
  function revive(value) {
    if (value && typeof value === "object") {
      if (value.__blobIndex !== undefined) {
        return blobs[value.__blobIndex];
      }

      if (Array.isArray(value)) {
        return value.map((v) => revive(v));
      }

      const out = {};
      for (const k in value) out[k] = revive(value[k]);
      return out;
    }
    return value;
  }

  return revive(JSON.parse(json));
}
```

#### Uploading only JSON

If no Blob type is in the request, we can continue as normal and upload straight JSON.

#### Determining Endpoint Media Type

We will need to define a `MediaType ` in the CIDL: `MediaType::Octet | MediaType::Json | MediaType::FormData`. Each method will have to mark its set of parameters under a `MediaType`, and its return value under a `MediaType`. We can do this in the generator portion, after intaking the `cidl.pre.json`, adding a media type to the end. The backend will then assume that the `MediaType` sent by the frontend is correct (or throw a `415`), and the client will assume that the server is sending the correct `MediaType`. Note that the server could return an error which would be text. if the server responds with the incorrect media type, we will want some fatal error to occur, as the generated code should always be synced (this should only happen if the `CIDL` was tampered with).

### R2

We've decided that we won't add anything to support uploading to R2 in this milestone (though a developer can easily make a `Stream` endpoint with the above section implemented). However, there is no reason we can't help with _downloading_ from R2.

Generally, R2 key information is stored in SQL associated with some metadata. This enters the domain of Models. As talked about in the previous section, Blobs cannot be streamed JSON data. But we can return a signed download URL to access the blob, along with all of the blob metadata. For directly supporting R2, I propose creating a new navigation property for this express purpose, and integrating it into our ORM.

First, we need to support the WranglerEnv and help with generating configs.. `R2Bucket`'s are the Wrangler API to interact with any R2 bucket. We can generate the toml bindings if buckets are defined. Key information will also be necessary for generating signed download URLs.

```ts
@WranglerEnv
class Env {
  someBucket: R2Bucket;
  anotherBucket: R2Bucket;
  endpoint: R2Endpoint;
  accessKeyId: R2AccessKeyId;
  secretAccessKey: R2SecretAccessKey;
}
```

producing a wrangler config:

```toml
[[r2_buckets]]
binding = "someBucket"
bucket_name = "someBucket"

[[r2_buckets]]
binding = "anotherBucket"
bucket_name = "anotherBucket"

[[vars]]
endpoint = "xxxx"
```

We will also want to generate a `.dev.vars` for sensitive info:

```toml
accessKeyId="xxxx"
secretAccessKey="xxxx"
```

Note that we cannot validate that the access key and secret access key exists at compile time. This is because production CF apps use `wrangler secret put SOME_KEY`, which Cloesce cannot access. We will have to check at runtime that the values exist.

#### Uploads

As talked about before, Cloesce isn't going to orchestrate a signed upload URL process. We will leave that to the user. However, if a developer wishes to not use a signed upload URL, they're always welcome to use the Blob type, or a Stream for large objects (or even orchestrate their own signed url process). For example:

```ts
@D1
class Comment {
  @PrimaryKey
  id: Integer;

  body: string;

  gif: string;

  @POST
  static async post(@Inject env: Env, comment: Comment, gif: Blob) {
    await this.env.someBucket.put("my key", gif);

    // ...
    await orm.upsert(Comment, {
      ...comment,
      gif: "my key",
    });
  }

  @POST
  async postBigGif(@Inject env: env, gif: Stream) {
    ...
    // note this is an instantiated method, posting a gif has to be done after an object is instantiated
    // for the stream to be allowed
  }
}
```

#### List, Get

To help with fetching content from R2, we will orchestrate the signed download URL creation process directly into our ORM. This must be done in the HLL layer of Cloesce, not in our Generator/Rust code.

```ts
@D1
@CRUD(["GET", "LIST"])
class Comment {
  @PrimaryKey
  id: Integer;

  body: string;

  gif: string;

  @R2({
    bucket: "someBucket",
    keyColumn: "gif",
  })
  gifDownloadUrl: R2Download | undefined;

  @DataSource
  static readonly withDownload: IncludeTree<Comment> {
    gifDownloadUrl: {
      // We should try to place the S3 Type "GetObjectRequest" in here
      // though I'm not sure if the TS type system would allow that.
      //
      // If impossible, we might just want to revamp how IncludeTrees are generated,
      // potentially creating a custom builder.
    }
  }
}

// where R2Download is some class
class R2Download {
  url: string;

  // metadata from `head object`
  size: number;
  etag: string;
  ...
  // https://docs.aws.amazon.com/AmazonS3/latest/API/API_HeadObject.html
}
```

With this navigation property `gifDownloadUrl` will be populated with metadata on the blob, along with the signed download url. Like the D1 navigation properties, R2 must be included with an IncludeTree, via a data source. The ORM function `mapSql` will have to populate download URLs if the include tree references them.

Note: Theres a lot of [different options](https://docs.aws.amazon.com/AWSJavaScriptSDK/v3/latest/client/s3/command/GetObjectCommand/) available when creating a signed url

```ts
const input = {
  // GetObjectRequest
  Bucket: "STRING_VALUE", // required
  IfMatch: "STRING_VALUE",
  IfModifiedSince: new Date("TIMESTAMP"),
  IfNoneMatch: "STRING_VALUE",
  IfUnmodifiedSince: new Date("TIMESTAMP"),
  Key: "STRING_VALUE", // required
  Range: "STRING_VALUE",
  ResponseCacheControl: "STRING_VALUE",
  ResponseContentDisposition: "STRING_VALUE",
  ResponseContentEncoding: "STRING_VALUE",
  ResponseContentLanguage: "STRING_VALUE",
  ResponseContentType: "STRING_VALUE",
  ResponseExpires: new Date("TIMESTAMP"),
  VersionId: "STRING_VALUE",
  SSECustomerAlgorithm: "STRING_VALUE",
  SSECustomerKey: "STRING_VALUE",
  SSECustomerKeyMD5: "STRING_VALUE",
  RequestPayer: "requester",
  PartNumber: Number("int"),
  ExpectedBucketOwner: "STRING_VALUE",
  ChecksumMode: "ENABLED",
};
```

# Summary of Changes

- Introduce Cloesce Services
- Add `Blob` SQL column type
- Add `Blob`, `Stream` CIDL Types
- Add `MediaType` enum for a methods parameters and return value
- Switch behavior on the router based off `MediaType`
- Switch behavior on the client API based off `MediaType`
- Add R2 Wrangler config generation / support
- Add R2 Navigation Property; Generate signed download URLs
